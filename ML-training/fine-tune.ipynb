{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dataset_path = './data/fer/'\n",
    "\n",
    "train_csv = dataset_path + 'train.csv'\n",
    "test_csv = dataset_path + 'test.csv'\n",
    "val_csv = dataset_path + 'val.csv'\n",
    "csv_file = dataset_path + 'fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Build the model\n",
    "def build_model(self):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(gpus[0])\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(self, extra_callbacks=[]):\n",
    "\n",
    "    root_path = self.root_path\n",
    "    learning_rate = self.learning_rate\n",
    "    batch_size= self.batch_size\n",
    "    epochs = self.epochs\n",
    "    img_size = self.img_size\n",
    "    postfix = self.postfix\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    adam = Adam(learning_rate)\n",
    "    self.model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    eval_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        root_path + \"/train\"+postfix,\n",
    "        target_size=(img_size, img_size),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        root_path + \"/val\"+postfix,\n",
    "        target_size=(img_size, img_size),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    eval_generator = eval_datagen.flow_from_directory(\n",
    "        root_path + \"/test\"+postfix,\n",
    "        target_size=(img_size, img_size),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    print(val_generator.class_indices)\n",
    "\n",
    "    es_cb = EarlyStopping(monitor='val_accuracy',\n",
    "        min_delta=0.00005,\n",
    "        patience=11,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    cp_cb = ModelCheckpoint(\n",
    "        filepath='model.h5',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "\n",
    "    history_fit = self.model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=800/(batch_size/32), #28709\n",
    "        epochs=epochs,\n",
    "        # validation_steps=2000,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[es_cb] + extra_callbacks,\n",
    "    )\n",
    "\n",
    "    history_predict = tqdm(self.model.evaluate(eval_generator, steps=2000))\n",
    "\n",
    "    #draw the graph\n",
    "    plot_history(history_fit)\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Plot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Plot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "def save_model(self):\n",
    "    root_path = self.root_path + '/fine-tune'\n",
    "    model_json = self.model.to_json()\n",
    "    with open(root_path+\"/model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    self.model.save_weights(root_path+\"/model_weight.h5\")\n",
    "    self.model.save(root_path+\"/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;  \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=5292)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "# Const variables\n",
    "img_size = 48\n",
    "num_classes = 7\n",
    "root_path = \"./data/fer\"\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "learning_rate=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Model:\n",
    "    img_size = 48\n",
    "    num_classes = 7\n",
    "    root_path = \"./data/fer\"\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    learning_rate=0.001\n",
    "    postfix = \"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        build_model(self)\n",
    "\n",
    "    def train_model(self, another_callback=[]):\n",
    "        train_model(self, another_callback)\n",
    "\n",
    "    def save_model(self):\n",
    "        save_model(self)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf\n",
    "from wandb.keras  import WandbCallback\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_size = 48\n",
    "    num_classes = 7\n",
    "    root_path = \"./data/fer\"\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    learning_rate=0.001\n",
    "    postfix = \"\"\n",
    "    wandb.init(project=\"fyp-fer-fine-tune\", entity=\"johnkhw\")\n",
    "    wandb.config = {\n",
    "        learning_rate,\n",
    "        epochs,\n",
    "        batch_size\n",
    "    }\n",
    "    wandb_callback = [\n",
    "        WandbCallback(),\n",
    "    ]\n",
    "    model = Model()\n",
    "    model.build_model()\n",
    "    model.train_model(wandb_callback)\n",
    "    model.save_model()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongk\\AppData\\Local\\Temp\\ipykernel_12892\\326642752.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # Conv2D layer\n",
    "    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "                     activation='relu',\n",
    "                     input_shape=(48, 48, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Conv2D layer\n",
    "    model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1_rate', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Flatten())\n",
    "    # Dense layer\n",
    "    model.add(Dense(units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16), activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    # Optimizer\n",
    "    optimizer_choice = hp.Choice('optimizer', ['sgd', 'adam'])\n",
    "    if optimizer_choice == 'sgd':\n",
    "        optimizer = SGD(lr=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'), decay=1e-6, momentum=0.9,nesterov=True)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# Set GPU memory limit\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=5292)]\n",
    "    )\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = './data/fer/'\n",
    "train_csv = dataset_path + 'train.csv'\n",
    "test_csv = dataset_path + 'test.csv'\n",
    "val_csv = dataset_path + 'val.csv'\n",
    "csv_file = dataset_path + 'fer2013.csv'\n",
    "\n",
    "# Load data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "eval_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path + \"/train\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dataset_path + \"/val\",\n",
    "    target_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "os.environ['WANDB_SILENT'] = 'true'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [01h 15m 03s]\n",
      "val_accuracy: 0.4524008532365163\n",
      "\n",
      "Best val_accuracy So Far: 0.5830779075622559\n",
      "Total elapsed time: 07h 51m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x000001F8BA0AE650>\n",
      "Best model saved as: ./data/fer\\model_v1.h5\n",
      "Found 3589 images belonging to 7 classes.\n",
      "  55/2000 [..............................] - ETA: 1:11 - loss: 1.1728 - accuracy: 0.5872WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s 1ms/step - loss: 1.1730 - accuracy: 0.5865\n",
      "Test set evaluation results: [1.1729532480239868, 0.5865143537521362]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img_size = 48\n",
    "    num_classes = 7\n",
    "    root_path = \"./data/fer\"\n",
    "    batch_size = 64\n",
    "    wandb.init(project=\"fyp-fer-fine-tune\", entity=\"johnkhw\")\n",
    "    # Hyperparameter tuning\n",
    "    tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=10,executions_per_trial=3,directory='output',project_name='fyp-fer-fine-tune',overwrite=True)\n",
    "    tuner.search(train_generator,\n",
    "                 steps_per_epoch=800/(batch_size/32),\n",
    "                 epochs=100,\n",
    "                 validation_data=val_generator,\n",
    "                 callbacks=[WandbCallback(), EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=11, verbose=0, restore_best_weights=True)])\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(best_hyperparameters)\n",
    "    \n",
    "    # Save the best model with a versioned file name\n",
    "    model_version = 1\n",
    "    model_path = os.path.join(root_path, f'model_v{model_version}.h5')\n",
    "    while os.path.exists(model_path):\n",
    "        model_version += 1\n",
    "        model_path = os.path.join(root_path, f'model_v{model_version}.h5')\n",
    "\n",
    "    best_model.save(model_path)\n",
    "    print(f\"Best model saved as: {model_path}\")\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    eval_generator = eval_datagen.flow_from_directory(\n",
    "        root_path + \"/test\",\n",
    "        target_size=(img_size, img_size),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "    results = best_model.evaluate(eval_generator, steps=2000)\n",
    "    print(f\"Test set evaluation results: {results}\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 44, 44, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 32)        51232     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9, 9, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2592)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               331904    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 385,703\n",
      "Trainable params: 385,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               819328    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 839,047\n",
      "Trainable params: 839,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show moel parameters\n",
    "best_model.summary()\n",
    "\n",
    "# load model\n",
    "old_model = keras.models.load_model('./data/fer/model.h5')\n",
    "old_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in output\\fyp-fer-fine-tune\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001F6ED9F3910>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 64\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 32\n",
      "conv_2_kernel: 5\n",
      "dropout_1_rate: 0.1\n",
      "dense_1_units: 128\n",
      "optimizer: adam\n",
      "learning_rate: 0.00036156986755960413\n",
      "Score: 0.5830779075622559\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 128\n",
      "conv_1_kernel: 3\n",
      "conv_2_filter: 48\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.1\n",
      "dense_1_units: 48\n",
      "optimizer: adam\n",
      "learning_rate: 0.00026152978239516096\n",
      "Score: 0.569239338239034\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 32\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.2\n",
      "dense_1_units: 96\n",
      "optimizer: adam\n",
      "learning_rate: 0.00010958136414612152\n",
      "Score: 0.5652456680933634\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 128\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 64\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.1\n",
      "dense_1_units: 48\n",
      "optimizer: adam\n",
      "learning_rate: 0.0021043482724264983\n",
      "Score: 0.530881385008494\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "conv_1_kernel: 3\n",
      "conv_2_filter: 32\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.1\n",
      "dense_1_units: 48\n",
      "optimizer: sgd\n",
      "learning_rate: 0.00093283405732218\n",
      "Score: 0.5186217029889425\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 80\n",
      "conv_1_kernel: 3\n",
      "conv_2_filter: 48\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.0\n",
      "dense_1_units: 96\n",
      "optimizer: adam\n",
      "learning_rate: 0.0031087381681937547\n",
      "Score: 0.5170428355534872\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 48\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 48\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.2\n",
      "dense_1_units: 112\n",
      "optimizer: adam\n",
      "learning_rate: 0.0029625809034809396\n",
      "Score: 0.5110058585802714\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 128\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 48\n",
      "conv_2_kernel: 3\n",
      "dropout_1_rate: 0.2\n",
      "dense_1_units: 112\n",
      "optimizer: sgd\n",
      "learning_rate: 0.00022451511351400015\n",
      "Score: 0.4524008532365163\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 48\n",
      "conv_1_kernel: 5\n",
      "conv_2_filter: 64\n",
      "conv_2_kernel: 5\n",
      "dropout_1_rate: 0.4\n",
      "dense_1_units: 112\n",
      "optimizer: sgd\n",
      "learning_rate: 0.0001311747725190237\n",
      "Score: 0.3673260807991028\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "conv_1_kernel: 3\n",
      "conv_2_filter: 48\n",
      "conv_2_kernel: 5\n",
      "dropout_1_rate: 0.2\n",
      "dense_1_units: 96\n",
      "optimizer: adam\n",
      "learning_rate: 0.009836804915578564\n",
      "Score: 0.357759823401769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conv_1_filter': 64,\n",
       " 'conv_1_kernel': 5,\n",
       " 'conv_2_filter': 32,\n",
       " 'conv_2_kernel': 5,\n",
       " 'dropout_1_rate': 0.1,\n",
       " 'dense_1_units': 128,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.00036156986755960413}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tuning results and all parameters\n",
    "tuner.results_summary()\n",
    "\n",
    "# show best hyperparameters\n",
    "best_hyperparameters.values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "515e3c4bb69b8fc5538ce8ee571d8d8518d28f831e5e7106b080a418fa73b22c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
